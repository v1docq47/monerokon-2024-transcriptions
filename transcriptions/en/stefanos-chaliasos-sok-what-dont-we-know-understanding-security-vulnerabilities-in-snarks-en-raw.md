# Stefanos Chaliasos

_**SoK: What don't we know? Understanding Security Vulnerabilities in SNARKs**_

_Zero-knowledge proofs (ZKPs) have evolved from being a theoretical concept providing privacy and verifiability to having practical, real-world implementations, with SNARKs (Succinct Non-Interactive Argument of Knowledge) emerging as one of the most significant innovations. Prior work has mainly focused on designing more efficient SNARK systems and providing security proofs for them. Many think of SNARKs as "just math," implying that what is proven to be correct and secure is correct in practice. In contrast, this paper focuses on assessing end-to-end security properties of real-life SNARK implementations. We start by building foundations with a system model and by establishing threat models and defining adversarial roles for systems that use SNARKs. Our study encompasses an extensive analysis of 141 actual vulnerabilities in SNARK implementations, providing a detailed taxonomy to aid developers and security researchers in understanding the security threats in systems employing SNARKs. Finally, we evaluate existing defense mechanisms and offer recommendations for enhancing the security of SNARK-based systems, paving the way for more robust and reliable implementations in the future._

[https://youtu.be/9RVL6jxMI5k](https://youtu.be/9RVL6jxMI5k)

---

_**Stefanos:**_ Thank you. So thanks a lot for the introduction. Let me say a few words about myself. I'm a PhD student, candidate at Imperial, but I'm also doing security audits for ZK security. My background is mainly from programming languages, computer security and privacy. But in the last few years, I have been working mainly on blockchain security, and especially smart contract security, and lately ZKP security, analyzing and benchmarking as virus ZKP frameworks, et cetera.

So in this talk, I'm going to present our latest work on zero knowledge proof vulnerabilities. And what does that mean? It means that when we use zero knowledge proof, some novel attacks might happen. So we'll give a brief motivation. Then I will discuss our mental model for systems using zero-knowledge proofs. Then I will discuss very briefly the impact of those vulnerabilities. I will present the threat model. And then I will present the main body of our work, which is a taxonomy for vulnerabilities in zero-knowledge proofs. And finally, we will very briefly discuss defenses.

So what is the state of zero-knowledge proofs? So zero-knowledge proof, for anyone that are not aware of them, are basically cryptographic protocols that allow to one party, the prover, to prove a statement to a verifier, potentially without revealing almost nothing about that statement. And that's what a zero-knowledge proof is.

The main use case for zero-knowledge proofs, obviously, is to use a protocol that has the zero-knowledge property. We will define what that property means in a bit, and that means having the ability to perform private transactions etc. But now these zero-knowledge proofs are mainly used for scalability. And what does it mean? It means that we have some blockchains that we call them Rollups or L2 blockchains, and in these blockchains we perform the computation of chain, and then we submit to an L1 blockchain a validity proof about the transactions we computed in another auxiliary block. And this is the main use of zero-knowledge proofs at the moment.

We also have Zcash, which is a layer one blockchain with private transactions. We have Filecoin that heavily uses zero-knowledge proofs, and we have some more applications. And despite that growing number of protocols and systems using them, we have not still observed an exploit, a black hat exploit of any of those protocols.

But there have been some very critical vulnerabilities in those protocols. For example, Zcash had a bug that was in the main deployment of Zcash for almost two years, and someone from inside detected that vulnerability and patched it. Tornado Cash had a very naive, I would say, vulnerability in one of the main circuits - circuits are the zero-knowledge proof programs, That's how we call them. That was again detected by a white hat hacker, and then it was exploited by the Tornado Cash team. Then in one of those zk Rollups there was a critical vulnerability that basically, if someone could exploit it, it could take all the TVL, all the value locked in that chain. And lately, one month ago, another vulnerability was detected in a system that is deployed, and that vulnerability was detected through an audit. So a few very critical vulnerabilities have been detected in the systems but none have been explored.

And the main reason why people believe this is the case is because they argue that zero-knowledge proofs are complex, writing circuits - it's even more complex, and also detecting vulnerabilities and perform attacks - it's even more complex. But we believe that with the recent developments and more and more people start using zero-knowledge proofs, writing circuits etc., vulnerabilities wouldn't be that hard to be detected and exploited. For example the ZCash vulnerability was due to an issue in one of the underlying libraries they used. And here is basically the program that was vulnerable. And the issue is in line 24, instead of using one symbol that means "assign a value and constraint", it only assigned that value. And that resulted to a vulnerability that if someone could have been exploited, would have been able to get all the money out of Tornado Cash.

So there has been some work into creating a taxonomy for zero-knowledge proof security issues. One initial effort was a bug tracker in GitHub by 0xPARÐ¡ and also some people have given some presentations discussing taxonomies about zero-knowledge proofs - one was from 2022, another one in 2024 - but there hasn't been like a systematic work into trying to better understand why we have the vulnerabilities and how to actually detect them. So we did that work. And the first part is to understand how systems using SNARKs and zero-knowledge proofs. So SNARKs are basically the most common zero-knowledge proofs used in practice today.

So we start with a program. Here we call it R, but it could be whatever. And that program basically describes what we want to prove - the computation that we want to prove to some verifier. And that program takes some public inputs and some private inputs. Then we need to manually translate that program and write a circuit. Typically we write circuits in domain specific languages for SNARKs. Some examples are Halo2, Circom, Manoir and many more. There are many, many DSLs today for writing SNARKs. And in those circuits we have to both define how to compute some values from some inputs, but also we have to constraint that computations to only accept the correct computation. And you can imagine that as putting assert statements in your code. And the computation part is performed by the prover and the verification part, the assertions are being evaluated by a verifier.

Then we have what we call the frontend, which basically takes as input the circuit and compiles down to two things. One is an intermediate representation that is going to be used as the input for our backend. And the other one is a witness generator, which basically takes the public and the private inputs, runs the computational logic from the circuit, and creates a trace with all the intermediate values and the final outputs of the circuit.

Then we have the backend. The backend is composed of three functions. The setup function, it takes some common reference string - we don't care in that work about that - and also it takes as the input the intermediate representation produced by the compiler. And then in that function, we create the keys - and that function is also called basically "preprocessing" - we create the keys, a prover key and a verifier key. And then we have two other functions. Prover takes as input the trace generated by the witness generator and the prover key and it creates a proof. And then the verifier takes as input only the public part of our trace, and because of the zero knowledge property some parts can be private, and it also takes the proof and the verification key and then it just outputs true or false if the proof can be verified.

And finally, we have the application layer, which is basically the layer where we are interacting with the SNARKs. And you can imagine that layer being a smart contract that calls on-chain verifier to see if a proof is correct or not. And another example for the integration layer could be some code that calls the prover etc.

Recently, there have been some novel frameworks called the ZK-VMs that basically abstract away the circuit part. So instead of writing ZKP circuits, you can just provide your program to ZK-VM, and everything else will work similar as before.

We can also imagine and think about those layers in the hierarchy where we have on the bottom level, the hardware, our runtime, etc. Then we have the proof system, which is basically the technical aspect, the theory for the SNARKs and the zero-knowledge proofs. On top of that, we need some very optimized fill arithmetic and elliptic curve libraries. And then we have the frontend, the backend, the circuit and the application. And any vulnerability in any of the lower levels means that basically everything that has been built upon that layer can be broken. And in that work we exclude the non-ZKP related vulnerabilities, layers.

So what are the main properties we care about in zero-knowledge proofs are knowledge soundness which means that a dishonest prover cannot convince that a verifier of an invalid statement, except with a negligible probability. The second property is that an honest prover can always convince an honest verifier of the correctness of a valid statement. So the verifier won't accept valid proofs if I manage to create a valid proof. And third, the zero-knowledge means that we cannot get any private information from the proof.

So our threat model has three main adversaries. The first one is the network adversary, which basically observes all the public messages that have been exchanged. And he cannot interact with neither the prover nor the verifier. Maybe he can extract some value if there's zero-knowledge, some private information, if the zero-knowledge property is broken. Then we have the adversarial user, which is a user that does not have proving capabilities. So it has to use a prover to generate a proof, but otherwise it can provide any input to the prover. And we have the adversarial prover, which is our main threat model, which means that a prover has the ability to arbitrarily produce a proof. And if the verifier is buggy, then it can break the soundness of our system. In our paper, we also explain a bit more about those adversarial roles and its capability that any adversary can have.

Ok, then what can go wrong? First, we can have a vulnerability that breaks the soundness of the zero-knowledge proof. And what does that mean? It means that a prover can convince a verifier of a false statement. Imagine the simplest example that we have a circuit that proves that a + b = c, and in that case the prover could convince the verifier that 1 + 1 = 5, which is wrong, and that means that it breaks the soundness.

Then we have breaking of completeness which means that we either cannot produce a valid proof for some valid statement or the verifier will reject some valid proofs, and finally where we can have a breaking of zero-knowledge, which means that we have information leakage about the private parts of the trace.

So in our work, we analyzed 141 vulnerabilities from either audit reports or vulnerability disclosures, or from bug trackers. We focused only into critical security vulnerabilities. We did not consider any non-ZKP related vulnerabilities. And here is a table presenting the main results.

So we categorize the vulnerabilities based on the layer and on the impact. And the main impact is soundness bugs, which is the worst thing that can happen into an application that uses zero-knowledge proofs, and also the most vulnerabilities are in the circuit layer. That could be because most of the effort is towards the circuit layer, but also it could be because of the different model that we have in the circuits.

And what I mean by different model is when you write a circuit, you have to have two things in your mind. First, the computation part. And in that example, we have two input variables, two temporary variables and one output variable. So when you read the circuit, you have to define the computation logic, how you compute a temporary variable three, temporary variable four and output five. But also you have to constraint your computations. And by constraining we mean what should be the value of temporary variable three, what should be the value of temporary variable four, and what should be the output variable. And this is a bit tricky and different than normal programming. And we believe that, and from our results we come to the conclusion that this is the main reason. The different threat model that developers should have is the main reason why we have so many vulnerabilities in the circuit layer. You can also imagine that the computation part is what is executed by the prover, and the constraints are what is checked by the verifier.

So what can go wrong in the circuit layer is that we can have underconstraint vulnerabilities, we can have overconstraint vulnerabilities, and we can have computational errors. Underconstraint means that somewhere we missed some constraint, so the prover can produce proofs of invalid statements. Overconstraint, it means that we have more constraints than those that we wanted to add, and that means that there could be some issues where we cannot produce proof for some statements, and computational is more on the logic side.

So we have a variety of root causes, and we have some tables in the paper that describe how many bugs has led from each root cause. But what I want to focus here is that there are two main root causes that we identified in the circuit layer.

First is that in some cases, as many constraints as you have in your circuit, that more expensive it will be to prove your circuit, given some inputs. So people have been trying to do various optimizations in that level, and this is one of the main reasons why we have so many bugs, and those optimizations are pretty complicated sometimes. And the second reason is that typically we work on a field when we're writing circuits and this is not the same field or the same integers that we have in our normal programs, and that also introduce some vulnerabilities.

I have two examples here, I will skip them, but we have many examples in our paper.

So next on the integration layer four main things could go wrong. First is passing and check data to the circuit, and that could happen because sometimes in the circuit we have some assumptions that we expect our inputs to have specific values or to be under a specific range, and it is on the integration layer to check for those assumptions. And in some cases people forget about those assumptions, because they are not that well documented or because it's a huge complicated system, and they forgot something.

And we also have proof delegation and proof composition errors, which has to do on how we use the prover. And also some of those applications, especially privacy related applications, have some complementary logic to the zero-knowledge proofs, and there can be some common vulnerabilities there.

Next on the frontend and on the backend we can have a number of vulnerabilities. And we go into the detail into the paper, but what I want you to get out of it is that if we have a frontend vulnerability, then even if our circuit is correct, then maybe it could be exploited. And the same stands for also backend vulnerabilities.

Now people have tried to create security tools to detect those vulnerabilities. Mainly they have been focused into the circuit layer, but because of the complexity of those systems and also the number of DSLs we have, the results are not that great. So many of the vulnerabilities cannot be detected and for some DSLs we have basically no support from a security tool. And also there hasn't been any effort on frontend and on the backend layers.

On top of that, what can go wrong is issues in the original descriptions of the zero-knowledge proofs in the original papers, and that could lead to various issues and then everything built on top of those proof systems will be vulnerable.

And so in conclusion - why do we have bugs in systems using zero-knowledge proofs? First is because zero-knowledge proofs are not just math, although they are based in very nice math. There could be bugs in the implementation that can break all the properties of the systems. And the second one is the reason - here I haveâ¦
