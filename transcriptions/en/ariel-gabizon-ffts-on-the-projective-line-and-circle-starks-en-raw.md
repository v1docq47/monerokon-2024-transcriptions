# Ariel Gabizon

_**FFT's on the projective line and circle-STARKs**_

_We'll review recent progress on FFT's from these papers that enables fast FFT's over Fp when a large power of two divides p+1. There is recent excitment about this because it enables using very convenient Mersenne prime fields of order 2^k-1._

[https://youtu.be/d1f9sBajj10](https://youtu.be/d1f9sBajj10)

---

_**Ariel:**_ Okay, so let's go over a little reminder of the classical FFT that probably is familiar. So we have some set of powers of some element g, and we assume the order of g is the power of 2. And we want to evaluate some polynomial of degree smaller than n on the points of S. So right, this is a pretty common thing we do when we do SNARKs.

And the basic trick, how we do this efficiently, is we decompose f to the even and odd coefficients. So we write f is like f even of X squared plus X times f odd of X squared. And why is this useful? f even and f odd are now polynomials of degree n over 2 instead of n. And also this mapping of going from X to X squared, when you apply it on the elements of S, then it's a 2 to 1 map. So we've reduced evaluating one polynomial of degree n at n points to evaluating two of polynomials of degree n over 2 at n over 2 points and again because S is of size a power of 2 we can continue this recursively, and that's what gives us the well-known n log FFT.

So I don't know what the background here of people, is that familiar? Does that compile? Thank you.

So personally, I'm happy with this. I don't know what more you need, but people are greedy. So some greedy people, they ask: "Well, this requires the power of 2 to divide p minus 1 to have such a g", which I think ok is fine. But say n instead of p minus 1 divides p plus 1, where p is the size of our field. Can we still have a fast FFT?

And the reason people care about this is they wanna work with fields where the p is as simple as possible when you're presented in base two. So the simplest possible p is a Mersenne prime of the form two to the k minus one. Like especially the Mersenne prime two to the 31 minus one is what a lot of SNARKs people are very excited about. So if you want to work with that, you won't have p minus 1 dividing a large power of 2, but obviously if it's a percent prime p plus 1, for example 2 to the 31 will contain a large power of 2. So can we do fast FFTs when n divides p plus 1?

So let's reflect a little abstractly on why the FFT works. So we have this map going from x to g times x. And what's nice about this map is that it goes over the set S as a cycle. It goes over when you keep up, you start from some point in S and you apply this map, it'll go over all the points in a cycle.

Now, because n is a power of 2 and this sigma is a cycle, if you now define the map tau to be sigma applied n over 2 times, so what will tau be? Well, in this case, it will simply be the map x goes to minus x. But simply from the fact that sigma was a cycle, we know two things. We know that tau has order two, meaning that if you apply it twice, you just get the identity map. So tau squared x is always x. And also we know that it must split S into disjoint pairs. If you look at pairs a, tau of a, the pairs will be disjoint. And one more thing we know, if we look at sort of - you can think it's called n because it sort of corresponds to norm maps of field extensions - if you look at the map going from x to x times tau of x. So this will simply be minus x squared in this case. Then this n maps the pairs into the same output. Because the pairs are like a, tau of a, then when you apply on that, x goes to x times tau of x, it must map, and tau is ordered too, it must map a and tau of a too, it must map the pairs to the same thing.

So this motivates the question: can we find a set of size p plus 1 and some operation sigma on it that is cyclical like this g is?

And this very naturally brings up what's called the projective line. So we want to have a set of size p plus one where our field is of size p. So a natural set to look at is what's called the projective line, which is simply taking your field and sort of adding the point at infinity.

And now, so we have this set, this little slightly weird set, F, the field union, the point at infinity. And we want to look at operations that can sort of cycle over this set. So the natural operations are the fractional maps. So we can take, look at a map sigma x that goes to 1 over a, x plus b. And then the question: "Ok, how is this map defined over p?" So the two points where it's like you're not sure what sigma should do, one point is sort of the pole, right? Sigma of minus b over a. You're going to get zero in the denominator. So we'll just define that sigma minus b over a as infinity. And then the question is: "Well, what is infinity mapped to?" So, right, it's sort of like 1 over infinity, so let's say sigma of infinity goes to 0.

And a claim that you can find in the paper of Li and Xing that this talk is based on is that you can find some a and b such that applying sigma will give you a cycle over all of P.

Ok, so now let's talk a little about, I mean, what is this F union infinity? Like, how do people formally represent the projective line? And we'll sort of go over three options.

So the first thing is projective coordinates. So you'll represent your field elements as the ratios, as pair c/d such that a is the ratio, c over d. And then, so for example, (a, 1) always represents a. So a field element now has multiple representatives. That's what's a little, sometimes complicated or annoying in the projective representation. And then, ok, when you represent things as ratios… So then when you have 0 as the right coordinate, then very naturally that'll be infinity. So the elements (a, 0), you'll think of them all as representatives of infinity.

And yeah, and one nice thing, I mean it's not too relevant to this talk, is that although an element has many representatives, you can use homogeneous polynomials and in a well-defined way, say what it means for a polynomial to operate over zero, over a projective point, independent of your choice of representative.

So projective coordinates, that's one way how people work with a projective line. And then another thing you can do is go from the line to the plane and look at a circle in the plane. And I don't know how clear this drawing is, so the idea is now we can map the points in the circle to the line. How by always starting at the north point of the circle. And now to say what a point in the circle maps to in the line, we draw a line for that point, see where it meets the line. And that gives us the mapping between the circle and the line. And then you can ask; ‘Well, so the point at the north of the circle, if you draw a tangent line to the circle, where will it meet the line?' And then we say; "Ok, that point is mapped at infinity." Or another way to do it is you take the infinite line, and you bend it into a circle. And then again, you get this sort of the north point of the circle is sort of mapped to the point infinity. And this paper "Circle STARK" this is sort of the approach it takes for describing these FFTs.

And now a third way to represent the projective line, and this is where it gets much more algebraic and abstract, is to represent the projective line as what's called the places of the field of rational functions.

So what does that mean? And the last part of this talk will be mainly to give you some feeling of what this means. So, we do people - remember the definition of ring? So a ring is a set of elements that's closed under addition and multiplication, but not necessarily inverse. So a valuation ring in the field K of rational functions is a sub ring where for every element in the field, either it's in the ring or it's inverse is in the ring, or both - that's fine. So this is what's called a valuation ring, right? Very sort of abstract, ad hoc definition at first glance. And what do these valuation rings look like?

So the main example is you choose some a in your base field. Sorry, that F should be like all the other Fs. And you look basically at the set of all functions that don't have a pole at a. So all f over g, where g of a is non-zero. And you can check that this is a ring that is closed under addition and multiplication. And you can check it really satisfies this definition because for any rational function, if it doesn't have a pole at a, so it's already in Ra. If it does, then well f over g, if you have f over g where g does have a pole at a - well, ok, so g over f will not have a pole at a. So this is sort of the ring of functions that are well defined at a. And these valuation rings, they're also called the places of K.

And so a cool thing is that you can sort of abstractly evaluate at a with this framework. So the unique maximal ideal of Ra will always be this set, which is just all the elements of Ra times X minus a. And the cool thing is if we want to evaluate some function Ra at a, we can define the evaluation as taking that function mod Ia. So that will give us some field element and this will be the result of this abstract sort of operation will be the same as just evaluating the function at a in the normal way.

Ok, but if you look at all - there's some way to define degree for these valuation rings. It's actually just when you take the ring mod, it's maximal ideal, it's going to be some algebraic extension of the base field. So in whatever the degree of the extension, that will be the degree of the place. And there's one more place in K in the field of rational functions that we can call R infinity. And this is all f over g such that the degree of f is smaller equal to the degree of g.

So, sorry, so you can think of our infinity is sort of as a set of functions that can be evaluated at infinity. If the degree of g is like at least the degree of f, then right when we go to infinity, in a sense, the value doesn't go to infinity, it goes to some finite. So it turns out where we start with this very abstract definition of what a valuation ring is, and it turned out that the valuation rings of degree one are exactly the points on the projective line.

Ok, so we started with talking about FFT and then we went to this really abstract notion of places. Again this is not something you can explain in 20 minutes, but very briefly what does this have to do with FFTs? So, right, if we go back a bit, what we needed, we wanted to do is we needed to represent our f as some combination of two functions fe(N(X)). Now, right n in the normal FFT, it's X squared. It's just X squared. But here in this context, since we're going to start with this fractional transformation instead of just X goes to g times x, n is going to be some degree two rational function. And we need to figure out how to combine, how to represent f as two elements that look like that with n of x inside that have half the degree, right? Where also the question is what does degree mean? So very briefly, the idea is that working with these concepts of valuation rings and what's called function fields and what's called Riemann-Roch spaces that, I didn't say anything about, it gives us very convenient tools to construct the right bases for representing f, fe and fo and also defining degree in a way that really like f, fe and fo will have half the degree of f as in the classical FFT.

Yeah, so for more details, look on the archive, it's by Li and Xing, the paper is called, I'm embarrassed to say I forgot the exact name of the paper, but something G-FFT, Galois FFT. All right, thank you very much.
